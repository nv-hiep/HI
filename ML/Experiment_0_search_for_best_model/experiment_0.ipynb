{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1486d1-7aec-4d45-90a4-6fb833d3f890",
   "metadata": {},
   "source": [
    "# Experiment 0: search for the best hyper parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d324c22-17d0-4bb5-bca0-94184d8c05df",
   "metadata": {},
   "source": [
    "### Using original vector as data representation. <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081866b4-7366-45ac-ac06-74225e0c154f",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff52966a-dd04-4a57-98f8-6fc9229ba46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from astropy.io          import fits\n",
    "from astropy             import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "from torch.optim.lr_scheduler import LambdaLR, StepLR, MultiStepLR, ExponentialLR\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "import CNN\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e801a294-9ae1-4dc7-877a-74e4a4cb8e53",
   "metadata": {},
   "source": [
    "# Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0882c7-fb79-42aa-a26d-83b3670bcad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator-1\\Desktop\\New folder (6)\\HI\\ML\\Experiment_0_search_for_best_model\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a207d748-2b1e-4601-a529-9b8f70f5d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_kok14_galfa = os.path.join(os.getcwd(),\"data\", \"other\", \"training_data_kok14_galfa.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b5bcd-f61b-4768-9c40-cfa0f93244e5",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c63b4d4-f34e-46ae-a999-e92ca6fe7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(training_data_kok14_galfa, 'rb'))\n",
    "\n",
    "# training data\n",
    "X_train = data['X_train']\n",
    "Y_train = data['Y_train']\n",
    "# Observed test data\n",
    "X_test = data['X_test']\n",
    "Y_test = data['Y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd67b511-f7b0-4881-b886-8e72da141d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, \n",
    "                                                    Y_train, \n",
    "                                                    test_size=0.2, \n",
    "                                                    shuffle = True, \n",
    "                                                    random_state = 8)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
    "                                                  y_train, \n",
    "                                                  test_size=0.25, \n",
    "                                                  random_state= 8) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc8b378-fa46-4f36-a01f-01b681ffc1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train= (23268, 414) , y_train= (23268, 2)\n",
      "x_val= (7756, 414) , y_val= (7756, 2)\n",
      "x_test= (7757, 414) , y_test= (7757, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train=\",x_train.shape, \", y_train=\", y_train.shape)\n",
    "print(\"x_val=\",x_val.shape, \", y_val=\", y_val.shape)\n",
    "print(\"x_test=\",x_test.shape, \", y_test=\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991842d7-9745-40ed-9baf-571c88cf9968",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f0487f-b151-49f4-a78e-8f5c7bee875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_loader\n",
    "# initialize dataset\n",
    "dataset_train = data_loader.spectra_loader(x_train, \n",
    "                                           y_train,\n",
    "                                           transform=data_loader.ToTensor(),\n",
    "                                           target_transform=data_loader.ToTensor(),\n",
    "                                           pe=None)\n",
    "\n",
    "dataset_val = data_loader.spectra_loader(x_val, \n",
    "                                         y_val,\n",
    "                                         transform=data_loader.ToTensor(),\n",
    "                                         target_transform=data_loader.ToTensor(),\n",
    "                                         pe=None)\n",
    "\n",
    "dataset_test = data_loader.spectra_loader(x_test,\n",
    "                                          y_test,\n",
    "                                          transform=data_loader.ToTensor(),\n",
    "                                          target_transform=data_loader.ToTensor(),\n",
    "                                          pe=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "814043cf-d51c-42c0-be8e-f1fb48093520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize data loader\n",
    "batch_size = 20 \n",
    "train_loader = torch.utils.data.DataLoader(dataset = dataset_train,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle =True)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(dataset = dataset_val,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle =False)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = dataset_test, \n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d34dc496-cfdc-4ce5-83d6-656fc24f6c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 1, 414])\n",
      "torch.Size([20, 2])\n"
     ]
    }
   ],
   "source": [
    "# test data loader\n",
    "val = iter(test_loader)\n",
    "A,B = next(val)\n",
    "print(A.shape)\n",
    "print(B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5aeac-6ad9-4084-ac2e-c4e59c166344",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6eddc66c-89d1-43f2-afc2-7c864676f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "def train(epoch):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : int.\n",
    "        the index of epoch.\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss/total: The mean MSE in an epoch. \n",
    "        \n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    for index, (inputs, values) in enumerate(train_loader):\n",
    "        inputs = inputs.float()\n",
    "        values = values.float()\n",
    "        inputs, values = inputs.to(device), values.to(device)\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, values)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print info\n",
    "        train_loss = train_loss + (loss.item()*values.size(0)) \n",
    "        total += values.size(0)\n",
    "    print('total loss = ', train_loss)\n",
    "    return train_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "73be50e0-5b05-4a55-8bc5-ff44ede46aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    \"\"\"\n",
    "    validate the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : int.\n",
    "        the index of epoch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error: The mean MSE in validation set. \n",
    "        \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    global best_err\n",
    "    test_loss = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for index, (inputs, values) in enumerate(valid_loader):\n",
    "            inputs = inputs.float()\n",
    "            values = values.float()\n",
    "            inputs, values = inputs.to(device), values.to(device)\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, values)\n",
    "            test_loss = test_loss + (loss.item()*values.size(0))\n",
    "            total += values.size(0)\n",
    "    # Save checkpoint.\n",
    "    error =  test_loss / total\n",
    "    print(f\"validation MSE in epoch {epoch}= \", error)\n",
    "    if error < best_err:\n",
    "        print('best_err:', error, 'Saving..')\n",
    "        state = {'net': model.state_dict(),\n",
    "                 'err': error,\n",
    "                 'optimizer_state_dict': optimizer.state_dict(),\n",
    "                 'epoch': epoch}\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/s2_no_pe.pth')\n",
    "        best_err = error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "16870f93-9b16-4bfa-88d0-d97b751b369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    \"\"\"\n",
    "    test the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : int.\n",
    "        the index of epoch.\n",
    "    Returns\n",
    "    -------\n",
    "    error: The mean MSE in test set. \n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    global best_err\n",
    "    test_loss = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for index, (inputs, values) in enumerate(test_loader):\n",
    "            inputs = inputs.float()\n",
    "            values = values.float()\n",
    "            inputs, values = inputs.to(device), values.to(device)\n",
    "            # forward \n",
    "            outputs = model(inputs)\n",
    "            #outputs = outputs.view(outputs[0], 1, outputs[1])\n",
    "            loss = loss_function(outputs, values)\n",
    "            test_loss =test_loss+ (loss.item()* values.size(0))\n",
    "            total += values.size(0)\n",
    "        return test_loss/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d0a92-b06d-45af-af84-edd762092236",
   "metadata": {},
   "source": [
    "## Start 10 trail Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5ead602e-c371-46f3-96c9-83a826c95455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(num_output=2,\n",
    "                   in_channels=1,\n",
    "                   input_row = 1,\n",
    "                   input_column=414,\n",
    "                   num_layer = 10,\n",
    "                   drop_out_rate=0.30,\n",
    "                   lpe=False):\n",
    "    global model\n",
    "    model =  CNN.spectra_cnn(num_output=num_output,\n",
    "                             in_channels=in_channels,\n",
    "                             input_row = input_row,\n",
    "                             input_column=input_column,\n",
    "                             num_layer = num_layer,\n",
    "                             drop_out_rate=drop_out_rate,\n",
    "                             lpe=lpe)\n",
    "    num_step = len(X_train)/batch_size\n",
    "    loss_function = nn.MSELoss()\n",
    "    best_err = 100000\n",
    "    checkpoint = torch.load('./checkpoint/s2_no_pe.pth',map_location=torch.device('cuda:0'))\n",
    "    model.load_state_dict(checkpoint['net'])\n",
    "    model.to(device)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    validation_error = validation(epoch)\n",
    "    test_error = test(epoch)\n",
    "    return validation_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "262b8983-5b2f-4b4b-b63b-4f3d7f25e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trail(num_epoch,\n",
    "          num_output=2,\n",
    "          in_channels=1,\n",
    "          input_row = 1,\n",
    "          input_column=414,\n",
    "          num_layer = 10,\n",
    "          drop_out_rate=0.30,\n",
    "          lpe=False):\n",
    "    \n",
    "    global vali\n",
    "    global testing\n",
    "    global scheduler\n",
    "    global model\n",
    "    global learning_rate\n",
    "    lr = learning_rate\n",
    "    #define savor\n",
    "    global train_trails\n",
    "    global validate_trails\n",
    "    global test_trails\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        train_err = train(epoch)\n",
    "        vali_err = validation(epoch)\n",
    "        scheduler.step()\n",
    "        test_err = test(epoch)\n",
    "        print('train_err=', train_err)\n",
    "        # save data\n",
    "        train_trails.append(train_err)\n",
    "        validate_trails.append(vali_err)\n",
    "        test_trails.append(test_err)\n",
    "    # final test\n",
    "    validation_error,test_error = validate_model(num_output=num_output,\n",
    "                                                 in_channels=in_channels,\n",
    "                                                 input_row = input_row,\n",
    "                                                 input_column=input_column,\n",
    "                                                 num_layer = num_layer,\n",
    "                                                 drop_out_rate=drop_out_rate,\n",
    "                                                 lpe=lpe)\n",
    "    print(\"test err=\",test_error)\n",
    "    vali.append(validation_error)\n",
    "    testing.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "40068930-97ec-4c83-8532-1f14a0bd80b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start 10 trails.\n",
    "def trail_10(num_trial,\n",
    "             num_epoch, \n",
    "             #\n",
    "             in_channels,\n",
    "             input_row,\n",
    "             input_column,\n",
    "             num_layer,\n",
    "             num_output=2,\n",
    "             drop_out_rate=0.3,\n",
    "             lpe=False):\n",
    "    \n",
    "    global learning_rate\n",
    "    global vali\n",
    "    global testing\n",
    "    global train_trails\n",
    "    global validate_trails\n",
    "    global test_trails\n",
    "    \n",
    "    for i in range (0, num_trial):\n",
    "        print(f'start the {i}th trial:')\n",
    "        # model initialization\n",
    "        lr=learning_rate\n",
    "    \n",
    "        model =  CNN.spectra_cnn(num_output=num_output,\n",
    "                             in_channels=in_channels,\n",
    "                             input_row = input_row,\n",
    "                             input_column=input_column,\n",
    "                             num_layer = num_layer,\n",
    "                             drop_out_rate=drop_out_rate,\n",
    "                             lpe=lpe)\n",
    "    \n",
    "        num_step = len(X_train)/batch_size\n",
    "        loss_function = nn.MSELoss()\n",
    "        best_err = 100000\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer, \n",
    "                                                     milestones = [65], \n",
    "                                                     gamma=0.1, last_epoch=-1, \n",
    "                                                     verbose=False)\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        trail(num_epoch = num_epoch,\n",
    "              input_row = input_row,\n",
    "              in_channels = in_channels,\n",
    "              input_column=input_column,\n",
    "              num_layer = num_layer,\n",
    "              drop_out_rate=drop_out_rate,\n",
    "              lpe=lpe,\n",
    "              num_output=num_output\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89609b5-cde5-42f5-b229-456aeeac0347",
   "metadata": {},
   "source": [
    "## Results display methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba9cef10-fe17-4093-bc5b-823eb58f1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_performance(vali):\n",
    "    x = vali\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.title('validation performance')\n",
    "    plt.plot(x, label='validation MSE',marker='o')\n",
    "    plt.plot([], [], ' ', label=f\"mean={round(np.mean(x),6)}\")\n",
    "    plt.plot([], [], ' ', label=f\"std={round(np.std(x),6)}\")\n",
    "    plt.xlabel('Trail')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print(\"validation mean=\",np.mean(x))\n",
    "    print(\"validation std=\",np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "22ab3632-1ebc-4ed5-9212-83ca17b0a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(testing):\n",
    "    x = testing\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.title('testing performance')\n",
    "    plt.plot(x, label='testing MSE',marker='o')\n",
    "    plt.plot([], [], ' ', label=f\"mean={round(np.mean(x),6)}\")\n",
    "    plt.plot([], [], ' ', label=f\"std={round(np.std(x),6)}\")\n",
    "    plt.xlabel('Trail')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print(\"testing mean=\",np.mean(x))\n",
    "    print(\"testing std=\",np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "175359aa-961f-4c7c-b13e-dfcb61f6c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vali_testing_performance_show(vali, testing):\n",
    "    x1 = vali\n",
    "    x2 = testing\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.title('Two in one')\n",
    "    plt.plot(x1, label='vaidation_MSE',marker='o')\n",
    "    plt.plot(x2, label='tesing_MSE',marker='o')\n",
    "    plt.xlabel('Trail')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74be7817-f2fd-457c-b178-2a2e903b7725",
   "metadata": {},
   "source": [
    "## Save csv methdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6ed51dfd-67a9-478a-ac94-d816476299f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(vali, testing, file_name_1, file_name_2):\n",
    "    x1 = np.array(vali).reshape(1, -1)\n",
    "    x2 = np.array(testing).reshape(1, -1)\n",
    "    two = np.vstack((x1,x2))\n",
    "    df = pd.DataFrame(two).T\n",
    "    df.to_csv(os.path.join(os.getcwd(),\"training_process\") + \"\\\\\" + file_name_1)\n",
    "    #\n",
    "    x3 = np.array(train_trails).reshape(1, -1)\n",
    "    x4 = np.array(validate_trails).reshape(1, -1)\n",
    "    x5 = np.array(test_trails).reshape(1, -1)\n",
    "    three = np.vstack((x3,x4,x5))\n",
    "    df = pd.DataFrame(three).T\n",
    "    df.to_csv(os.path.join(os.getcwd(),\"training_process\") + \"\\\\\"+ file_name_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4f97d-9b5b-4f09-8b57-1e9dc88d218b",
   "metadata": {},
   "source": [
    "## Start training for layer number = [2, 4, 6, 8, 10, 12, 14, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fe64f08c-1123-4d87-b8f8-3f20789080cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layer = [2, 4, 6, 8, 10, 12, 14, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a42c73d7-e39a-4846-8c56-a4c50e831658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_layer= 2\n",
      "start the 0th trial:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m test_trails \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_layer=\u001b[39m\u001b[38;5;124m\"\u001b[39m, i)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mtrail_10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_trial\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m         \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;66;43;03m#\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m         \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m         \u001b[49m\u001b[43minput_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m         \u001b[49m\u001b[43minput_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m414\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m         \u001b[49m\u001b[43mnum_layer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m         \u001b[49m\u001b[43mnum_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdrop_out_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlpe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m validation_performance(vali)\n\u001b[0;32m     22\u001b[0m test_performance(testing)\n",
      "Cell \u001b[1;32mIn[79], line 43\u001b[0m, in \u001b[0;36mtrail_10\u001b[1;34m(num_trial, num_epoch, in_channels, input_row, input_column, num_layer, num_output, drop_out_rate, lpe)\u001b[0m\n\u001b[0;32m     41\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 43\u001b[0m \u001b[43mtrail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_layer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdrop_out_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_out_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlpe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlpe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_output\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m     \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[78], line 22\u001b[0m, in \u001b[0;36mtrail\u001b[1;34m(num_epoch, num_output, in_channels, input_row, input_column, num_layer, drop_out_rate, lpe)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m test_trails\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epoch):\n\u001b[1;32m---> 22\u001b[0m     train_err \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     vali_err \u001b[38;5;241m=\u001b[39m validation(epoch)\n\u001b[0;32m     24\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[74], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, values)\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# print info\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in num_layer:\n",
    "    learning_rate = 0.005\n",
    "    # the savier of best validation performance and coresponding testing performance.\n",
    "    vali = []\n",
    "    testing = []\n",
    "    # saver for each trials\n",
    "    train_trails = []\n",
    "    validate_trails =[]\n",
    "    test_trails = []\n",
    "    print(\"num_layer=\", i)\n",
    "    trail_10(num_trial = 10,\n",
    "             num_epoch = 80, \n",
    "             #\n",
    "             in_channels = 1,\n",
    "             input_row=1,\n",
    "             input_column=414,\n",
    "             num_layer = i,\n",
    "             num_output=2,\n",
    "             drop_out_rate=0.3,\n",
    "             lpe=False)\n",
    "    validation_performance(vali)\n",
    "    test_performance(testing)\n",
    "    vali_testing_performance_show(vali, testing)\n",
    "    file_name_1 = f'num_layer_{i}.csv'\n",
    "    file_name_1 = f'num_layer_{i}_process.csv'\n",
    "    save_csv(vali, testing, file_name_1, file_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0323308e-d015-491f-89c9-f5743dd8c4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca6ba38-0645-4bcd-a933-2c81382ad5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325118f1-469b-4f4e-83d1-8a044abd55d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
