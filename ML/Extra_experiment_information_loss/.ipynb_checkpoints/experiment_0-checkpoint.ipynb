{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f1486d1-7aec-4d45-90a4-6fb833d3f890",
   "metadata": {},
   "source": [
    "# Experiment: Information Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d324c22-17d0-4bb5-bca0-94184d8c05df",
   "metadata": {},
   "source": [
    "### Using original vector as data representation. <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081866b4-7366-45ac-ac06-74225e0c154f",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff52966a-dd04-4a57-98f8-6fc9229ba46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from astropy.io          import fits\n",
    "from astropy             import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "from torch.optim.lr_scheduler import LambdaLR, StepLR, MultiStepLR, ExponentialLR\n",
    "import os\n",
    "import argparse\n",
    "import data_loader\n",
    "\n",
    "import glob\n",
    "import pickle\n",
    "import CNN\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e801a294-9ae1-4dc7-877a-74e4a4cb8e53",
   "metadata": {},
   "source": [
    "# Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0882c7-fb79-42aa-a26d-83b3670bcad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator-1\\Desktop\\New folder (6)\\HI\\ML\\Extra_experiment_information_loss\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a207d748-2b1e-4601-a529-9b8f70f5d912",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_kok14_galfa = os.path.join(os.getcwd(),\"data\", \"other\", \"training_data_kok14_galfa.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65b5bcd-f61b-4768-9c40-cfa0f93244e5",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c63b4d4-f34e-46ae-a999-e92ca6fe7ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(training_data_kok14_galfa, 'rb'))\n",
    "\n",
    "# training data\n",
    "X_train = data['X_train']\n",
    "Y_train = data['Y_train']\n",
    "# Observed test data\n",
    "X_test = data['X_test']\n",
    "Y_test = data['Y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd67b511-f7b0-4881-b886-8e72da141d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_train, \n",
    "                                                    Y_train, \n",
    "                                                    test_size=0.2, \n",
    "                                                    shuffle = True, \n",
    "                                                    random_state = 8)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train,\n",
    "                                                  y_train, \n",
    "                                                  test_size=0.25, \n",
    "                                                  random_state= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dc8b378-fa46-4f36-a01f-01b681ffc1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train= (23268, 414) , y_train= (23268, 2)\n",
      "x_val= (7756, 414) , y_val= (7756, 2)\n",
      "x_test= (7757, 414) , y_test= (7757, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train=\",x_train.shape, \", y_train=\", y_train.shape)\n",
    "print(\"x_val=\",x_val.shape, \", y_val=\", y_val.shape)\n",
    "print(\"x_test=\",x_test.shape, \", y_test=\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5aeac-6ad9-4084-ac2e-c4e59c166344",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eddc66c-89d1-43f2-afc2-7c864676f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "def train(epoch):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : int.\n",
    "        the index of epoch.\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss/total: The mean MSE in an epoch. \n",
    "        \n",
    "    \"\"\"\n",
    "    global model\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    for index, (inputs, values) in enumerate(train_loader):\n",
    "        inputs = inputs.float()\n",
    "        values = values.float()\n",
    "        inputs, values = inputs.to(device), values.to(device)\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, values)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print info\n",
    "        train_loss = train_loss + (loss.item()*values.size(0)) \n",
    "        total += values.size(0)\n",
    "    print('total loss = ', train_loss)\n",
    "    return train_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73be50e0-5b05-4a55-8bc5-ff44ede46aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(epoch):\n",
    "    \"\"\"\n",
    "    validate the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : int.\n",
    "        the index of epoch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error: The mean MSE in validation set. \n",
    "        \n",
    "    \"\"\"\n",
    "    global model\n",
    "    model.eval()\n",
    "    global best_err\n",
    "    test_loss = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for index, (inputs, values) in enumerate(valid_loader):\n",
    "            inputs = inputs.float()\n",
    "            values = values.float()\n",
    "            inputs, values = inputs.to(device), values.to(device)\n",
    "            # forward\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, values)\n",
    "            test_loss = test_loss + (loss.item()*values.size(0))\n",
    "            total += values.size(0)\n",
    "    # Save checkpoint.\n",
    "    error =  test_loss / total\n",
    "    print(f\"validation MSE in epoch {epoch}= \", error)\n",
    "    if error < best_err:\n",
    "        print('best_err:', error, 'Saving..')\n",
    "        state = {'net': model.state_dict(),\n",
    "                 'err': error,\n",
    "                 'optimizer_state_dict': optimizer.state_dict(),\n",
    "                 'epoch': epoch}\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/s2_no_pe.pth')\n",
    "        best_err = error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16870f93-9b16-4bfa-88d0-d97b751b369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    \"\"\"\n",
    "    test the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    epoch : int.\n",
    "        the index of epoch.\n",
    "    Returns\n",
    "    -------\n",
    "    error: The mean MSE in test set. \n",
    "    \"\"\"\n",
    "    global model\n",
    "    model.eval()\n",
    "    global best_err\n",
    "    test_loss = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for index, (inputs, values) in enumerate(test_loader):\n",
    "            inputs = inputs.float()\n",
    "            values = values.float()\n",
    "            inputs, values = inputs.to(device), values.to(device)\n",
    "            # forward \n",
    "            outputs = model(inputs)\n",
    "            #outputs = outputs.view(outputs[0], 1, outputs[1])\n",
    "            loss = loss_function(outputs, values)\n",
    "            test_loss =test_loss+ (loss.item()* values.size(0))\n",
    "            total += values.size(0)\n",
    "        return test_loss/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d0a92-b06d-45af-af84-edd762092236",
   "metadata": {},
   "source": [
    "## Start 10 trail Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ead602e-c371-46f3-96c9-83a826c95455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(num_output=2,\n",
    "                   in_channels=1,\n",
    "                   input_row = 1,\n",
    "                   input_column=414,\n",
    "                   num_layer = 8,\n",
    "                   drop_out_rate=0.30,\n",
    "                   lpe=False):\n",
    "    global model\n",
    "    model =  CNN.spectra_cnn(num_output=num_output,\n",
    "                             in_channels=in_channels,\n",
    "                             input_row = input_row,\n",
    "                             input_column=input_column,\n",
    "                             num_layer = num_layer,\n",
    "                             drop_out_rate=drop_out_rate,\n",
    "                             lpe=lpe)\n",
    "    num_step = len(X_train)/batch_size\n",
    "    loss_function = nn.MSELoss()\n",
    "    best_err = 100000\n",
    "    checkpoint = torch.load('./checkpoint/s2_no_pe.pth',map_location=torch.device('cuda:0'))\n",
    "    model.load_state_dict(checkpoint['net'])\n",
    "    model.to(device)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    validation_error = validation(epoch)\n",
    "    test_error = test(epoch)\n",
    "    return validation_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "262b8983-5b2f-4b4b-b63b-4f3d7f25e05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trail(num_epoch,\n",
    "          num_output=2,\n",
    "          in_channels=1,\n",
    "          input_row = 1,\n",
    "          input_column=414,\n",
    "          num_layer = 8,\n",
    "          drop_out_rate=0.30,\n",
    "          lpe=False):\n",
    "    \n",
    "    global vali\n",
    "    global testing\n",
    "    global scheduler\n",
    "    global model\n",
    "    global learning_rate\n",
    "    lr = learning_rate\n",
    "    #define savor\n",
    "    global train_trails\n",
    "    global validate_trails\n",
    "    global test_trails\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        train_err = train(epoch)\n",
    "        vali_err = validation(epoch)\n",
    "        scheduler.step()\n",
    "        test_err = test(epoch)\n",
    "        print('train_err=', train_err)\n",
    "        # save data\n",
    "        train_trails.append(train_err)\n",
    "        validate_trails.append(vali_err)\n",
    "        test_trails.append(test_err)\n",
    "    # final test\n",
    "    validation_error,test_error = validate_model(num_output=num_output,\n",
    "                                                 in_channels=in_channels,\n",
    "                                                 input_row = input_row,\n",
    "                                                 input_column=input_column,\n",
    "                                                 num_layer = num_layer,\n",
    "                                                 drop_out_rate=drop_out_rate,\n",
    "                                                 lpe=lpe)\n",
    "    print(\"test err=\",test_error)\n",
    "    vali.append(validation_error)\n",
    "    testing.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40068930-97ec-4c83-8532-1f14a0bd80b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start 10 trails.\n",
    "def trail_10(num_trial,\n",
    "             num_epoch, \n",
    "             #\n",
    "             in_channels,\n",
    "             input_row,\n",
    "             input_column,\n",
    "             num_layer,\n",
    "             num_output=2,\n",
    "             drop_out_rate=0.3,\n",
    "             lpe=False):\n",
    "    \n",
    "    global learning_rate\n",
    "    global vali\n",
    "    global testing\n",
    "    global train_trails\n",
    "    global validate_trails\n",
    "    global test_trails\n",
    "    global model\n",
    "    global optimizer\n",
    "    global best_err\n",
    "    global scheduler\n",
    "    for i in range (0, num_trial):\n",
    "        print(f'start the {i}th trial:')\n",
    "        # model initialization\n",
    "        lr=learning_rate\n",
    "        model =  CNN.spectra_cnn(num_output=num_output,\n",
    "                             in_channels=in_channels,\n",
    "                             input_row = input_row,\n",
    "                             input_column=input_column,\n",
    "                             num_layer = num_layer,\n",
    "                             drop_out_rate=drop_out_rate,\n",
    "                             lpe=lpe)\n",
    "    \n",
    "        num_step = len(X_train)/batch_size\n",
    "        loss_function = nn.MSELoss()\n",
    "        best_err = 100000\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer, \n",
    "                                                     milestones = [65], \n",
    "                                                     gamma=0.1, last_epoch=-1, \n",
    "                                                     verbose=False)\n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        trail(num_epoch = num_epoch,\n",
    "              input_row = input_row,\n",
    "              in_channels = in_channels,\n",
    "              input_column=input_column,\n",
    "              num_layer = num_layer,\n",
    "              drop_out_rate=drop_out_rate,\n",
    "              lpe=lpe,\n",
    "              num_output=num_output\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89609b5-cde5-42f5-b229-456aeeac0347",
   "metadata": {},
   "source": [
    "## Results display methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba9cef10-fe17-4093-bc5b-823eb58f1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_performance(vali):\n",
    "    x = vali\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.title('validation performance')\n",
    "    plt.plot(x, label='validation MSE',marker='o')\n",
    "    plt.plot([], [], ' ', label=f\"mean={round(np.mean(x),6)}\")\n",
    "    plt.plot([], [], ' ', label=f\"std={round(np.std(x),6)}\")\n",
    "    plt.xlabel('Trail')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print(\"validation mean=\",np.mean(x))\n",
    "    print(\"validation std=\",np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22ab3632-1ebc-4ed5-9212-83ca17b0a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(testing):\n",
    "    x = testing\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.title('testing performance')\n",
    "    plt.plot(x, label='testing MSE',marker='o')\n",
    "    plt.plot([], [], ' ', label=f\"mean={round(np.mean(x),6)}\")\n",
    "    plt.plot([], [], ' ', label=f\"std={round(np.std(x),6)}\")\n",
    "    plt.xlabel('Trail')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    print(\"testing mean=\",np.mean(x))\n",
    "    print(\"testing std=\",np.std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "175359aa-961f-4c7c-b13e-dfcb61f6c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vali_testing_performance_show(vali, testing):\n",
    "    x1 = vali\n",
    "    x2 = testing\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.title('Two in one')\n",
    "    plt.plot(x1, label='vaidation_MSE',marker='o')\n",
    "    plt.plot(x2, label='tesing_MSE',marker='o')\n",
    "    plt.xlabel('Trail')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74be7817-f2fd-457c-b178-2a2e903b7725",
   "metadata": {},
   "source": [
    "## Save csv methdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ed51dfd-67a9-478a-ac94-d816476299f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(vali, testing, file_name_1, file_name_2):\n",
    "    x1 = np.array(vali).reshape(1, -1)\n",
    "    x2 = np.array(testing).reshape(1, -1)\n",
    "    two = np.vstack((x1,x2))\n",
    "    df = pd.DataFrame(two).T\n",
    "    df.to_csv(os.path.join(os.getcwd(),\"training_process\") + \"\\\\\" + file_name_1)\n",
    "    #\n",
    "    x3 = np.array(train_trails).reshape(1, -1)\n",
    "    x4 = np.array(validate_trails).reshape(1, -1)\n",
    "    x5 = np.array(test_trails).reshape(1, -1)\n",
    "    three = np.vstack((x3,x4,x5))\n",
    "    df = pd.DataFrame(three).T\n",
    "    df.to_csv(os.path.join(os.getcwd(),\"training_process\") + \"\\\\\"+ file_name_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4f97d-9b5b-4f09-8b57-1e9dc88d218b",
   "metadata": {},
   "source": [
    "## Decimals = [1, 2, 4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe64f08c-1123-4d87-b8f8-3f20789080cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Decimals = [1, 2, 4, 6, 8, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a42c73d7-e39a-4846-8c56-a4c50e831658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decimal= 1\n",
      "start the 0th trial:\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 58\u001b[0m\n\u001b[0;32m     52\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset \u001b[38;5;241m=\u001b[39m dataset_test,\n\u001b[0;32m     53\u001b[0m                                       batch_size \u001b[38;5;241m=\u001b[39m batch_size,\n\u001b[0;32m     54\u001b[0m                                       shuffle \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     56\u001b[0m loss_function \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m---> 58\u001b[0m \u001b[43mtrail_10\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_trial\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m         \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;66;43;03m#\u001b[39;49;00m\n\u001b[0;32m     61\u001b[0m \u001b[43m         \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m         \u001b[49m\u001b[43minput_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m         \u001b[49m\u001b[43minput_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m414\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m         \u001b[49m\u001b[43mnum_layer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m         \u001b[49m\u001b[43mnum_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m         \u001b[49m\u001b[43mdrop_out_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlpe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m validation_performance(vali)\n\u001b[0;32m     69\u001b[0m test_performance(testing)\n",
      "Cell \u001b[1;32mIn[12], line 45\u001b[0m, in \u001b[0;36mtrail_10\u001b[1;34m(num_trial, num_epoch, in_channels, input_row, input_column, num_layer, num_output, drop_out_rate, lpe)\u001b[0m\n\u001b[0;32m     43\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 45\u001b[0m \u001b[43mtrail\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_row\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m      \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_layer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdrop_out_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_out_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlpe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlpe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_output\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m     \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 22\u001b[0m, in \u001b[0;36mtrail\u001b[1;34m(num_epoch, num_output, in_channels, input_row, input_column, num_layer, drop_out_rate, lpe)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m test_trails\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epoch):\n\u001b[1;32m---> 22\u001b[0m     train_err \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     vali_err \u001b[38;5;241m=\u001b[39m validation(epoch)\n\u001b[0;32m     24\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[7], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     19\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     20\u001b[0m values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m---> 21\u001b[0m inputs, values \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, values\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# forward\u001b[39;00m\n\u001b[0;32m     23\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:221\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "for i in Decimals:\n",
    "    global  learning_rate\n",
    "    learning_rate = 0.005\n",
    "    global vali\n",
    "    global testing\n",
    "    global train_trails\n",
    "    global validate_trails\n",
    "    global test_trails\n",
    "    # the savier of best validation performance and coresponding testing performance.\n",
    "    vali = []\n",
    "    testing = []\n",
    "    # saver for each trials\n",
    "    train_trails = []\n",
    "    validate_trails =[]\n",
    "    test_trails = []\n",
    "    global device\n",
    "    device = 'cuda:0'\n",
    "    global loss_function\n",
    "    global batch_size\n",
    "    batch_size=20\n",
    "    # initialize dataset\n",
    "    print('decimal=', i)\n",
    "    dataset_train = data_loader.spectra_loader(x= x_train, \n",
    "                                               y = y_train, \n",
    "                                               transform=data_loader.ToTensor(),\n",
    "                                               target_transform=data_loader.ToTensor(),\n",
    "                                               pe=None, \n",
    "                                               decimal = i)\n",
    "    \n",
    "    dataset_val = data_loader.spectra_loader(x= x_val, \n",
    "                                               y = y_val, \n",
    "                                               transform=data_loader.ToTensor(),\n",
    "                                               target_transform=data_loader.ToTensor(),\n",
    "                                               pe=None, \n",
    "                                               decimal = i)\n",
    "    \n",
    "    dataset_test = data_loader.spectra_loader(x= x_test,\n",
    "                                               y = y_test, \n",
    "                                               transform=data_loader.ToTensor(),\n",
    "                                               target_transform=data_loader.ToTensor(),\n",
    "                                               pe=None,\n",
    "                                               decimal = i)\n",
    "    # initialize data loader\n",
    "    train_loader = torch.utils.data.DataLoader(dataset = dataset_train,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle =True)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset = dataset_val,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle =False)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset = dataset_test,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle =False)\n",
    "    \n",
    "    loss_function = nn.MSELoss()\n",
    "    \n",
    "    trail_10(num_trial = 10,\n",
    "             num_epoch = 80, \n",
    "             #\n",
    "             in_channels = 1,\n",
    "             input_row=1,\n",
    "             input_column=414,\n",
    "             num_layer = 8,\n",
    "             num_output=2,\n",
    "             drop_out_rate=0.3,\n",
    "             lpe=False)\n",
    "    validation_performance(vali)\n",
    "    test_performance(testing)\n",
    "    vali_testing_performance_show(vali, testing)\n",
    "    file_name_1 = f'decimal_{i}.csv'\n",
    "    file_name_2 = f'decimal_{i}_process.csv'\n",
    "    save_csv(vali, testing, file_name_1, file_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ce5ea5-94e2-4543-9e4e-6337ac3a2ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f902c5-90aa-4832-a50b-e36125de6f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64e794-d7fb-4198-87b2-c7cf3ecf8b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb11395-49ee-4164-818c-149b4422955b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d492d6-c5ac-46c6-897d-d904baea3760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
